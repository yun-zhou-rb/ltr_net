{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RankNet as described in [1].\n",
    "[1] http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf\n",
    "\n",
    "[2] https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#binary case 1--> relevant 0--> no relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k=10, method=0):\n",
    "        \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> dcg_at_k(r, 1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 1, method=1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 2)\n",
    "        5.0\n",
    "        >>> dcg_at_k(r, 2, method=1)\n",
    "        4.2618595071429155\n",
    "        >>> dcg_at_k(r, 10)\n",
    "        9.6051177391888114\n",
    "        >>> dcg_at_k(r, 11)\n",
    "        9.6051177391888114\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Discounted cumulative gain\n",
    "        \"\"\"\n",
    "        r = np.asfarray(r)[:k]\n",
    "        if r.size > 0:\n",
    "            if method == 0:\n",
    "                return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "            elif method == 1:\n",
    "                return float(np.sum(r / np.log2(np.arange(2, r.size + 2))))\n",
    "            else:\n",
    "                raise ValueError('method must be 0 or 1.')\n",
    "        return 0.\n",
    "def ndcg_at_k(r, k=10, method=0):\n",
    "        \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> ndcg_at_k(r, 1)\n",
    "        1.0\n",
    "        >>> r = [2, 1, 2, 0]\n",
    "        >>> ndcg_at_k(r, 4)\n",
    "        0.9203032077642922\n",
    "        >>> ndcg_at_k(r, 4, method=1)\n",
    "        0.96519546960144276\n",
    "        >>> ndcg_at_k([0], 1)\n",
    "        0.0\n",
    "        >>> ndcg_at_k([1], 2)\n",
    "        1.0\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Normalized discounted cumulative gain\n",
    "        \"\"\"\n",
    "        dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "        if not dcg_max:\n",
    "            return 0.\n",
    "        return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.\n",
    "input_dim = 10\n",
    "n_docs = 20\n",
    "n_rel2 = 5\n",
    "n_rel1 = 5\n",
    "n_irr = n_docs - n_rel2 - n_rel1\n",
    "y=np.array([2]*n_rel2+[1]*n_rel1+[0]*n_irr)\n",
    "unique, unique_index = np.unique(y, return_index=True)\n",
    "unique=np.flip(unique,axis=0).copy()\n",
    "unique = torch.from_numpy(unique)\n",
    "unique_index=np.flip(unique_index,axis=0).copy()\n",
    "unique_index = torch.from_numpy(unique_index)\n",
    "unique = unique.to(device)\n",
    "unique_index = unique_index.to(device)\n",
    "doc_features = np.random.randn(n_docs, input_dim)\n",
    "\n",
    "# Document scores.\n",
    "docs = torch.from_numpy(np.array(doc_features, dtype = \"float32\"))\n",
    "docs = docs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([4,2,7,1])\n",
    "order = array.argsort()\n",
    "ranks = order.argsort()\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2583],\n",
      "        [-0.2655],\n",
      "        [-0.2136],\n",
      "        [-0.1797],\n",
      "        [-0.1465],\n",
      "        [-0.2270],\n",
      "        [-0.2163],\n",
      "        [-0.1936],\n",
      "        [-0.2347],\n",
      "        [-0.2194],\n",
      "        [-0.2321],\n",
      "        [-0.2318],\n",
      "        [-0.2109],\n",
      "        [-0.1941],\n",
      "        [-0.2284],\n",
      "        [-0.2004],\n",
      "        [-0.2136],\n",
      "        [-0.1858],\n",
      "        [-0.2284],\n",
      "        [-0.2483]], device='cuda:0', grad_fn=<ThAddmmBackward>) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<ClampBackward>)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Model.\n",
    "L1=128//2\n",
    "L2=64//2\n",
    "L3=32//2\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(input_dim, L1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(L1, L2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(L2, L3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(L3, 1))\n",
    "\n",
    "model = model.to(device)\n",
    "doc_scores = model(docs)\n",
    "norm_doc_scores=doc_scores.clamp(0,1000)\n",
    "print(doc_scores,norm_doc_scores)\n",
    "ndcg_before=ndcg_at_k(norm_doc_scores.view(-1).tolist())\n",
    "print(ndcg_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : tensor([-103.6479], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "100 : tensor([-1.8127], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "200 : tensor([-0.3489], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "300 : tensor([-0.1657], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "400 : tensor([-0.1035], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "500 : tensor([-0.0734], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "600 : tensor([-0.0561], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "700 : tensor([-0.0450], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "800 : tensor([-0.0373], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "900 : tensor([-0.0317], device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "Finished Training\n",
      "tensor([[ 6.5048],\n",
      "        [ 8.1659],\n",
      "        [ 7.6849],\n",
      "        [ 8.7419],\n",
      "        [ 7.7385],\n",
      "        [-1.5256],\n",
      "        [-2.2626],\n",
      "        [-1.0826],\n",
      "        [-1.5735],\n",
      "        [-2.9881],\n",
      "        [-0.7554],\n",
      "        [-1.1041],\n",
      "        [-3.2397],\n",
      "        [-1.7115],\n",
      "        [-0.3968],\n",
      "        [-1.3025],\n",
      "        [-1.2773],\n",
      "        [-1.0550],\n",
      "        [-0.6758],\n",
      "        [-0.1930]], device='cuda:0', grad_fn=<ThAddmmBackward>)\n",
      "tensor([[ 6.5048],\n",
      "        [ 8.1659],\n",
      "        [ 7.6849],\n",
      "        [ 8.7419],\n",
      "        [ 7.7385],\n",
      "        [-1.5256],\n",
      "        [-2.2626],\n",
      "        [-1.0826],\n",
      "        [-1.5735],\n",
      "        [-2.9881],\n",
      "        [-0.7554],\n",
      "        [-1.1041],\n",
      "        [-3.2397],\n",
      "        [-1.7115],\n",
      "        [-0.3968],\n",
      "        [-1.3025],\n",
      "        [-1.2773],\n",
      "        [-1.0550],\n",
      "        [-0.6758],\n",
      "        [-0.1930]], device='cuda:0', grad_fn=<ThAddmmBackward>) tensor([[6.5048],\n",
      "        [8.1659],\n",
      "        [7.6849],\n",
      "        [8.7419],\n",
      "        [7.7385],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0', grad_fn=<ClampBackward>)\n",
      "0.957407750353\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "loss = torch.zeros(1)\n",
    "loss = loss.to(device)\n",
    "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    # forward\n",
    "    doc_scores = model(docs)\n",
    "    loss = torch.zeros(1).to(device)\n",
    "    for idx, ui in enumerate(unique_index[1:]):\n",
    "        o_ij=doc_scores[:n_rel2]-doc_scores[n_rel2:].view(-1)\n",
    "        c_ij = o_ij - torch.log(1.0+torch.exp(o_ij))\n",
    "        loss+=c_ij.sum()\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update model weights.\n",
    "    lr = 0.001\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param += lr * param.grad\n",
    "\n",
    "    # print statistics\n",
    "    if epoch % (n_epoch//10) ==0:\n",
    "        print(f\"{epoch} : {loss}\")\n",
    "          \n",
    "\n",
    "print('Finished Training')\n",
    "doc_scores = model(docs)\n",
    "print(doc_scores)\n",
    "norm_doc_scores=doc_scores.clamp(0,1000)\n",
    "print(doc_scores,norm_doc_scores)\n",
    "ndcg_after=ndcg_at_k(norm_doc_scores.view(-1).tolist())\n",
    "print(ndcg_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586438533458532"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k=5, method=1):\n",
    "        \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> dcg_at_k(r, 1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 1, method=1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 2)\n",
    "        5.0\n",
    "        >>> dcg_at_k(r, 2, method=1)\n",
    "        4.2618595071429155\n",
    "        >>> dcg_at_k(r, 10)\n",
    "        9.6051177391888114\n",
    "        >>> dcg_at_k(r, 11)\n",
    "        9.6051177391888114\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Discounted cumulative gain\n",
    "        \"\"\"\n",
    "        r = np.asfarray(r)[:k]\n",
    "        if r.size > 0:\n",
    "            if method == 0:\n",
    "                return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "            elif method == 1:\n",
    "                return float(np.sum(r / np.log2(np.arange(2, r.size + 2))))\n",
    "            else:\n",
    "                raise ValueError('method must be 0 or 1.')\n",
    "        return 0.\n",
    "def ndcg_at_k(r, k=5, method=1):\n",
    "        \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> ndcg_at_k(r, 1)\n",
    "        1.0\n",
    "        >>> r = [2, 1, 2, 0]\n",
    "        >>> ndcg_at_k(r, 4)\n",
    "        0.9203032077642922\n",
    "        >>> ndcg_at_k(r, 4, method=1)\n",
    "        0.96519546960144276\n",
    "        >>> ndcg_at_k([0], 1)\n",
    "        0.0\n",
    "        >>> ndcg_at_k([1], 2)\n",
    "        1.0\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Normalized discounted cumulative gain\n",
    "        \"\"\"\n",
    "        dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "        if not dcg_max:\n",
    "            return 0.\n",
    "        return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.29433584,  3.48503256,  3.47028828,  4.27507067,  3.61133909,\n",
       "       -4.2266221 , -9.12169266, -4.79133892, -5.19874191, -7.19841385,\n",
       "       -6.83355951, -4.91971636, -6.3450489 , -4.39710379, -4.91532278,\n",
       "       -5.30558538, -5.02252579, -6.02778721, -5.38184261, -6.263484  ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores_arr=np.array(doc_scores.view(-1).tolist())\n",
    "doc_scores_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 17, 16, 19, 18, 14,  0, 12,  8,  1,  2, 10,  3, 13, 11,  7,  9,\n",
       "        5,  6,  4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = doc_scores_arr.argsort()\n",
    "ranks = order.argsort()\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
